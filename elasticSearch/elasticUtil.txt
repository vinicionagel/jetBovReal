No entanto, Elasticsearch é muito mais do que apenas Lucene e muito mais do que “apenas” pesquisa de texto completo. Também pode ser descrito da seguinte forma:

- Um armazenamento de documentos em tempo real distribuído onde cada campo é indexado e pesquisável

- Um mecanismo de pesquisa distribuído com análises em tempo real

- Capaz de escalar para centenas de servidores e petabytes de dados estruturados e não estruturados


Elasticsearch é orientado a documentos , o que significaque armazena objetos ou documentos inteiros. Ele não apenas os armazena, mas também indexa o conteúdo de cada documento para torná-los pesquisáveis.


--Métodos simples de consulta:

Para fazer isso, usaremos um método de pesquisa leve que é fácil de usar na linha de comando. Este método é frequentemente referido comouma pesquisa de string de consulta , já que passamos a pesquisa como um parâmetro de string de consulta de URL:

GET /megacorp/employee/_search?q=last_name:Smith

Elasticsearch fornece uma linguagem de consulta rica e flexível chamada DSL de consulta , que nos permite construir consultas muito mais complexas e robustas.

--Consulta com dsl

O idioma específico do domínio (DSL) éespecificado usando um corpo de solicitação JSON. Podemos representar a pesquisa anterior para todos os Smiths da seguinte forma:

GET /megacorp/employee/_search
{
    "query" : {
        "match" : {
            "last_name" : "Smith"
        }
    }
}

-- Subir elastic no docker --

docker run -p 9200:9200 -p 9300:9300 -e "discovery.type=single-node" docker.elastic.co/elasticsearch/elasticsearch:6.8.19

----

Vamos complicar um pouco a pesquisa. Ainda queremos encontrar todos os funcionários com o sobrenome Smith, mas queremos apenas funcionários com mais de 30 anos.
Nossa consulta mudará um pouco para acomodar um filtro , que nos permite executar pesquisas estruturadas com eficiência:

{
    "query" : {
        "filtered" : {
            "filter" : {
                "range" : {
                    "age" : { "gt" : 30 } 1
                }
            },
            "query" : {
                "match" : {
                    "last_name" : "smith" 2
                }
            }
        }
    }
}

 -- Match trata parecido por exemplo buscar que gosta de escalada:

{
"query" : {
        "match" : {
            "about" : "rock climbing"
        }
    }
}

Irá retornar quem curte rock tbm... para contornarmos isso é preciso buscar a palavra igual por meio do:

"match_phrase" : {
            "about" : "rock climbing"
        }


-- Destacando nossas pesquisas --



{
  "query" : {
    "match_phrase" : {
      "about" : "rock climbing"
    }
  },
  "highlight": {
    "fields" : {
      "about" : {}
    }
  }
}

Dessa forma vai trazer o le contém um trecho de texto do aboutcampo com as palavras correspondentes embrulhadas em <em></em> tags HTML.

--Analytics

Elasticsearch tem uma funcionalidade chamada agregações , quepermitem que você gere análises sofisticadas sobre seus dados.
É semelhante ao GROUP BY SQL, mas muito mais poderoso.



Essas agregações não são pré-calculadas; eles são gerados instantaneamente a partir dos documentos que correspondem à consulta atual


--Natureza distribuida

Embora nosso tutorial tenha dado exemplos de como usar o Elasticsearch, ele não tocou na mecânica.
Elasticsearch é distribuído por natureza e foi projetado para ocultar a complexidade que vem com a distribuição.

Elasticsearch se esforça para esconder a complexidade dos sistemas distribuídos.
Aqui estão algumas das operações que acontecem automaticamente nos bastidores:

Capítulo 3. Entrada de Dados, Saída de Dados

Elasticsearch é um armazenamento de documentos distribuído .Ele pode armazenar e recuperar estruturas de dados complexas - serializadas como documentos JSON - em tempo real .
Em outras palavras, assim que um documento é armazenado no Elasticsearch, ele pode ser recuperado de qualquer nó do cluster.

No Elasticsearch, todos os dados em cada campo são indexados por padrão .Ou seja, cada campo tem um índice invertido dedicado para recuperação rápida.

Um documento não consiste apenas em seus dados.Ele também tem metadados -informações sobre o documento.
Os três elementos de metadados necessários são os seguintes:

_index
Onde o documento mora

_type
A classe de objeto que o documento representa

_id
O identificador único do documento

Nome do índice: Este nome deve estar em minúsculas, não pode começar com sublinhado e não pode conter vírgulas.
Vamos usar websitecomo nosso nome de índice.

Por exemplo, se nosso índice for chamado website, nosso tipo for chamado bloge escolhermos o ID 123, a solicitação de índice terá a seguinte aparência:

PUT /website/blog/123
{
  "title": "My first blog entry",
  "text":  "Just trying this out...",
  "date":  "2014/01/01"
}


IDs de geração automática
Se nossos dados não tiverem um ID natural, podemos deixar o Elasticsearch gerar um para nós automaticamente. A estrutura da solicitação muda:
em vez de usar o PUT verbo ( “guardar este documento nesta URL”), usamos o POSTverbo ( “guardar este documento sob este URL”).

Exemplo:

POST /website/blog/
{
  "title": "My second blog entry",
  "text":  "Still trying this out...",
  "date":  "2014/01/01"
}

Recuperando um Documento:

GET / site / blog / 123? pretty

Adicionando prettyaos parâmetros de string de consulta para qualquer solicitação,
como no exemplo anterior, faz com que Elasticsearch imprima bem oResposta JSON para torná-lo mais legível.

Recuperando Parte de um Documento:

Ou se quiser apenas o _sourcecampo sem metadados, você pode usar o _sourceendpoint.

GET / website / blog / 123 / _source

Verificar se existe um documento

Se tudo o que você deseja fazer é verificar se um documento existe...

curl -i -XHEAD http://localhost:9200/website/blog/123

retorna um 200 se assim o doc existir, se não existir retorna

---------------Atualizando um documento inteiro---------------

Os documentos no Elasticsearch são imutáveis ; não podemos mudá-los.Em vez disso, se precisarmos atualizar um documento existente,
nós o reindexamos ou substituímos,que podemos fazer usando a mesma index.

Exemplo atualização

PUT /website/blog/123
{
  "title": "My first blog entry",
  "text":  "I am starting to get the hang of this...",
  "date":  "2014/01/02"
}


Internamente, o Elasticsearch marcou o documento antigo como excluído e adicionou um documento inteiramente novo.
A versão antiga do documento não desaparece imediatamente, embora você não consiga acessá-la.
O Elasticsearch limpa os documentos excluídos em segundo plano à medida que você continua a indexar mais dados.

---------------Criando um Novo Documento---------------

No entanto, se já temos um _idque queremos usar, então temos de dizer ElasticSearch que ele deve aceitar o nosso pedido índice apenas se um documento com o mesmo _index, _typee _idainda não existir.

Exemplo de chamada:

PUT /website/blog/123?op_type=create
{ ... }

OU

PUT /website/blog/123/_create
{ ... }

Caso existir retorna um 409

{
  "error" : "DocumentAlreadyExistsException[[website][4] [blog][123]:
             document already exists]",
  "status" : 409
}

------------Atualizações parciais de documentos------

O updateAPI deve obedecer às mesmas regras. Externamente, parece que estamos atualizando parcialmente um documento no local.
Internamente, no entanto, a updateAPI simplesmente gerencia o mesmo processo de recuperação-alteração-reindexação que já descrevemos.

A forma mais simples da updatesolicitação aceita um documento parcial como docparâmetro, que apenas é mesclado com o documento existente.

Exemplo:

POST /website/blog/1/_update
{
   "doc" : {
      "tags" : [ "testing" ],
      "views": 0
   }
}

---------------Usando scripts para fazer atualizações parciais---------------

Para aqueles momentos em que a API não é suficiente, o Elasticsearch permite que você escreva sua própria lógica personalizada em um script.
O script é compatível com muitas APIs, incluindo pesquisa, classificação, agregações e atualizações de documentos.
Os scripts podem ser passados como parte da solicitação, recuperados do .scripts índice especial ou carregados do disco.
A linguagem de script padrão é Groovy.


---------------Excluindo um Documento---------------

A sintaxe para excluir um documento segue o mesmo padrão que já vimos, mas usa o DELETE método:

DELETE /website/blog/123

-----Recuperando vários documentos-----
Por mais rápido que o Elasticsearch seja, ele pode ser ainda mais rápido.Combinar várias solicitações em uma evita a sobrecarga da rede de processar cada solicitação individualmente.
Se você sabe que precisa recuperar vários documentos do Elasticsearch,
é mais rápido recuperá-los todos em uma única solicitação usando o multi-get , ou mgetAPI, em vez de documento por documento.

A mgetAPI espera uma docsmatriz, cadaelemento que especifica o _index... Exemplo:

GET /_mget
{
   "docs" : [
      {
         "_index" : "website",
         "_type" :  "blog",
         "_id" :    2
      },
      {
         "_index" : "website",
         "_type" :  "pageviews",
         "_id" :    1,
         "_source": "views"
      }
   ]
}

O corpo da resposta também contém uma docsmatrizque contém uma resposta por documento...

{
   "docs" : [
      {
         "_index" :   "website",
         "_id" :      "2",
         "_type" :    "blog",
         "found" :    true,
         "_source" : {
            "text" :  "This is a piece of cake...",
            "title" : "My first external blog entry"
         },
         "_version" : 10
      },
      {
         "_index" :   "website",
         "_id" :      "1",
         "_type" :    "pageviews",
         "found" :    true,
         "_version" : 2,
         "_source" : {
            "views" : 2
         }
      }
   ]
}




---Lidando com Conflitos---

Ao atualizar um documento com a indexAPI,
lemos o documento original, fazemos nossas alterações e, em seguida, reindexamos todo o documento de uma vez.


No mundo do banco de dados, duas abordagens são comumente usadas para garantir que as mudanças não sejam perdidas ao fazer atualizações simultâneas:

Controle de concorrência pessimista
Amplamente usado por bancos de dados relacionais, essa abordagem pressupõe que mudanças conflitantes podem acontecer e,
portanto, bloqueia o acesso a um recurso para evitar conflitos.
Um exemplo típico é bloquear uma linha antes de ler seus dados, garantindo que apenas o encadeamento que colocou o bloqueio seja capaz de fazer alterações nos dados dessa linha.

Controle de concorrência otimista
Usado por Elasticsearch, essa abordagem pressupõe que é improvável que os conflitos ocorram e não impede que as operações sejam tentadas.
No entanto, se os dados subjacentes foram modificados entre a leitura e a gravação, a atualização falhará. Cabe então ao aplicativo decidir como deve resolver o conflito.
Por exemplo, ele pode tentar novamente a atualização, usando os dados novos, ou pode relatar a situação ao usuário.


Um _version número que é incrementado sempre que um documento é alterado.
Elasticsearch usa esse _versionnúmero para garantir que as alterações sejam aplicadas na ordem correta.
Se uma versão mais antiga de um documento chegar após uma nova versão, ela pode ser simplesmente ignorada.

---Controle de simultaneidade otimista*--


Vamos criar uma nova postagem no blog:

PUT /website/blog/1/_create
{
  "title": "My first blog entry",
  "text":  "Just trying this out..."
}

O corpo da resposta nos diz que este documento recém-criado possui _version número 1.

Agora, quando tentamos salvar nossas alterações reindexando o documento, especificamos o versionao qual nossas alterações devem ser aplicadas:


PUT /website/blog/1?version=1 1
{
  "title": "My first blog entry",
  "text":  "Starting to get the hang of this..."
}

Essa solicitação é bem-sucedida e o corpo da resposta nos diz que o _version foi incrementado para 2...


No entanto, se tivéssemos de executar novamente a mesma solicitação de índice, ainda especificando version=1, Elasticsearch responderia com um 409 Conflictcódigo de resposta HTTP.

Isso nos diz que o _version número atual do documento no Elasticsearch é 2, mas que especificamos que estávamos atualizando a versão 1.

Todas as APIs que atualizam ou excluem um documento aceitam um version parâmetro, o que permite que você aplique o controle de simultaneidade otimista apenas às partes do seu código onde faz sentido.


--------Usando versões de um sistema externo-----

Se seu banco de dados principal já tiver números de versão - ou um valor como timestampesse pode ser usado como um número de versão - você pode reutilizar esses mesmos números de versão no Elasticsearch adicionando version_type=externalà string de consulta.
Os números da versão devem ser inteiros maiores que zero e menores que cerca de 9.2e+18- um longvalor positivo em Java.

Como o elastic verifica:

Em vez de verificar se o atual _versioné o mesmo especificado na solicitação, o Elasticsearch verifica se o atual _versioné menor que a versão especificada.

**Os números de versão externa podem ser especificados não apenas nas solicitações de indexação e exclusão, mas também na criação de novos documentos.

Exemplo de criação com external:

PUT /website/blog/2?version=5&version_type=external
{
  "title": "My first external blog entry",
  "text":  "Starting to get the hang of this..."
}

Agora, atualizamos este documento, especificando um novo versionnúmero de 10:

PUT /website/blog/2?version=10&version_type=external
{
  "title": "My first external blog entry",
  "text":  "This is a piece of cake..."
}
**Se você executasse novamente esta solicitação, ela falharia com o mesmo erro de conflito que vimos antes, porque o número da versão externa especificada não é maior do que a versão atual no Elasticsearch.
Dessa forma vai atualizando de acordo com o que é passado na version external.

---Atualizações parciais de documentos

Também dissemos que os documentos são imutáveis: não podem ser alterados, apenas substituídos. A updateAPI deve obedecer às mesmas regras.
Externamente, parece que estamos atualizando parcialmente um documento no local.
Internamente, no entanto, a updateAPI simplesmente gerencia o mesmo processo de recuperação-alteração-reindexação que já descrevemos

A forma mais simples da update solicitação aceita um documento parcial como docparâmetro, que apenas é mesclado com o documento existente.

Por exemplo, poderíamos adicionar um tagscampo e um viewscampo à postagem do nosso blog da seguinte maneira:

POST /website/blog/1/_update
{
   "doc" : {
      "tags" : [ "testing" ],
      "views": 0
   }
}

------Recuperando vários documentos


A mgetAPI espera uma docsmatriz, cadaelemento que especifica o _index, _typee _id metadados do documento que você deseja recuperar.
Você também pode especificar um _source parâmetro se quiser apenas recuperar um ou mais campos específicos:

GET /_mget
{
   "docs" : [
      {
         "_index" : "website",
         "_type" :  "blog",
         "_id" :    2
      },
      {
         "_index" : "website",
         "_type" :  "pageviews",
         "_id" :    1,
         "_source": "views"
      }
   ]
}

O corpo da resposta também contém uma docs matriz que contém uma resposta por documento, na mesma ordem especificada na solicitação,
resposta que esperaríamos de uma get solicitação individual...

Exemplo chamada com vários documentos:

Na verdade, se todos os documentos tiverem o mesmo _indexe _type, você poderá simplesmente passar uma matriz de em idsvez da docsmatriz completa :

GET /website/blog/_mget
{
   "ids" : [ "2", "1" ]
}

Observe que o segundo documento que solicitamos não existe.
Especificamos o tipo blog, mas o documento com ID 1é do tipo pageviews. Essa inexistência é relatada no corpo da resposta:


{
  "docs" : [
    {
      "_index" :   "website",
      "_type" :    "blog",
      "_id" :      "2",
      "_version" : 10,
      "found" :    true,
      "_source" : {
        "title":   "My first external blog entry",
        "text":    "This is a piece of cake..."
      }
    },
    {
      "_index" :   "website",
      "_type" :    "blog",
      "_id" :      "1",
      "found" :    false  1
    }
  ]
}

O código de status HTTP para a solicitação anterior é 200, embora um documento não tenha sido encontrado.
Na verdade, ainda seria 200 se nenhum dos documentos solicitados fosse encontrado -  porque a mget própria solicitação foi concluída com êxito.
Para determinar o sucesso ou falha dos documentos individuais, você precisa verificara found bandeira.


------------Bulk------------------

Exemplo de bulk...

POST /_bulk
{ "delete": { "_index": "website", "_type": "blog", "_id": "123" }} 1
{ "create": { "_index": "website", "_type": "blog", "_id": "123" }}
{ "title":    "My first blog post" }
{ "index":  { "_index": "website", "_type": "blog" }}
{ "title":    "My second blog post" }
{ "update": { "_index": "website", "_type": "blog", "_id": "123", "_retry_on_conflict" : 3} }
{ "doc" : {"title" : "My updated blog post"} }


Observe como a deleteação não possui um corpo de solicitação; ele é seguido imediatamente por outra ação.

A resposta do Elasticsearch contém a itemsmatriz, que lista o resultado de cada solicitação, na mesma ordem em que os solicitamos:

{
   "took": 4,
   "errors": false, <<<< indica que todos foram executados com sucesso!
   "items": [
      {  "delete": {
            "_index":   "website",
            "_type":    "blog",
            "_id":      "123",
            "_version": 2,
            "status":   200,
            "found":    true
      }},
      {  "create": {
            "_index":   "website",
            "_type":    "blog",
            "_id":      "123",
            "_version": 3,
            "status":   201
      }},
      {  "create": {
            "_index":   "website",
            "_type":    "blog",
            "_id":      "EiwfApScQiiy7TIKFxRCTw",
            "_version": 1,
            "status":   201
      }},
      {  "update": {
            "_index":   "website",
            "_type":    "blog",
            "_id":      "123",
            "_version": 4,
            "status":   200
      }}
   ]
}}



IMPORTANTE ---> Cada sub-solicitação é executada de forma independente, portanto, a falha de uma sub-solicitação não afetará o sucesso das outras.

Se alguma das solicitações falhar, a errorsinalização de nível superior será definida como true

Exemplo com erro:

POST /_bulk
{ "create": { "_index": "website", "_type": "blog", "_id": "123" }}
{ "title":    "Cannot create - it already exists" }
{ "index":  { "_index": "website", "_type": "blog", "_id": "123" }}
{ "title":    "But we can update it" }

Na resposta, podemos ver que não foi possível create documentar 123 porque já existe, mas a index solicitação subsequente , também no documento 123, foi bem-sucedida:

{
   "took": 3,
   "errors": true, <<<< indica que teve erro
   "items": [
      {  "create": {
            "_index":   "website",
            "_type":    "blog",
            "_id":      "123",
            "status":   409, <<< solicitacao com erro
            "error":    "DocumentAlreadyExistsException <<<< exception
                        [[website][4] [blog][123]:
                        document already exists]"
      }},
      {  "index": {
            "_index":   "website",
            "_type":    "blog",
            "_id":      "123",
            "_version": 5,
            "status":   200 <<<< outra requisição foi OK!
      }}
   ]
}

IMPORTANTEEEEEEE:

Isso também significa que os bulk pedidos não são atômicos: eles não podem ser usados para implementar transações.
Cada solicitação é processada separadamente, portanto, o sucesso ou a falha de uma solicitação não interfere nas outras.


Talvez você esteja indexando dados de registro de indexação em lote no mesmo indexe com o mesmo type.
Ter deespecificar os mesmos metadados para cada documento é um desperdício.
Em vez disso, assim como para a mgetAPI, a bulksolicitação aceita um padrão /_indexou /_index/_typeno URL:


--Exemplo bulk para o mesmo indice--

POST /website/log/_bulk
{ "index": {}}
{ "event": "User logged in" }
{ "index": { "_type": "blog" }}
{ "title": "Overriding the default type" }


Toda a solicitação em massa precisa ser carregada na memória pelo nó que recebe nossa solicitação,
portanto, quanto maior a solicitação, menos memória disponível para outras solicitações...

Existe um tamanho ideal de solicitação em massa. Acima desse tamanho,
o desempenho não melhora mais e pode até cair. O tamanho ideal, entretanto, não é um número fixo.

Felizmente, é fácil encontrar este ponto ideal: tente indexar documentos típicos em lotes de tamanho crescente.
Quando o desempenho começa a cair, o tamanho do lote é muito grande.
Um bom lugar para começar é com lotes de 1.000 a 5.000 documentos ou, se os seus documentos forem muito grandes, com lotes ainda menores.

Muitas vezes, é útil ficar de olho no tamanho físico de suas solicitações em massa.
Mil documentos de 1 KB são muito diferentes de mil documentos de 1 MB. Um bom tamanho em massa para começar a jogar é em torno de 5 a 15 MB.

-------Encaminhando um documento para um fragmento----

Quando você indexa um documento, ele é armazenado em um único fragmento primário.Como o Elasticsearch sabe a qual fragmento um documento pertence?
Quando criamos um novo documento, como ele sabe se deve armazenar esse documento no fragmento 1 ou no fragmento 2?

O processo não pode ser aleatório, pois podemos precisar recuperar o documento no futuro. Na verdade, é determinado por uma fórmula simples:

shard = hash (roteamento)% number_of_primary_shards

Todas as APIs de documentos ( get, index, delete, bulk, update, e mget) aceitar um routingparâmetroque pode ser usado para personalizar o mapeamento de documento para fragmento.
Um valor de roteamento personalizado pode ser usado para garantir que todos os documentos relacionados - por exemplo,
todos os documentos pertencentes ao mesmo usuário - sejam armazenados no mesmo fragmento


--------Padrões de documentos múltiplos-------------

Os padrões para as APIs mget e bulk são semelhantes aos de documentos individuais. A diferença é que o nó solicitante sabe em qual fragmento reside cada documento.
Ele divide a solicitação de vários documentos em uma solicitação de vários documentos por fragmento e os encaminha em paralelo para cada nó participante.

--------Por que o formato engraçado?--------

Por que a bulk API exige o formato engraçado com os caracteres de nova linha, em vez de apenas enviar as solicitações agrupadas em uma matriz JSON, como a mget API?

Se as solicitações individuais fossem agrupadas em uma matriz JSON, isso significaria que precisaríamos fazer o seguinte:

Analise o JSON em uma matriz (incluindo os dados do documento, que podem ser muito grandes)

Observe cada solicitação para determinar para qual fragmento ela deve ir

Crie uma série de solicitações para cada fragmento

Serialize essas matrizes no formato de transporte interno

Envie os pedidos para cada fragmento

Funcionaria, mas precisaria de muita RAM para manter cópias essencialmente dos mesmos dados e criaria muito mais estruturas de dados que a Java Virtual Machine (JVM) teria para gastar tempo coletando lixo.

Em vez disso, o Elasticsearch alcança o buffer de rede, onde a solicitação bruta foi recebida, e lê os dados diretamente. Ele usa os caracteres de nova linha para identificar e analisar apenas as pequenas action/metadatalinhas a fim de decidir qual fragmento deve lidar com cada solicitação.

Essas solicitações brutas são encaminhadas diretamente para o fragmento correto. Não há cópia redundante de dados, nem estruturas de dados perdidas. Todo o processo de solicitação é tratado na menor quantidade de memória possível.

-----------------Buscas elasticSearch---------------------------------


Até agora, aprendemos como usar o Elasticsearch como um armazenamento simples de documentos distribuídos no estilo NoSQL.
Podemos jogar documentos JSON no Elasticsearch e recupere cada um por ID.
Mas o verdadeiro poder do Elasticsearch está em sua capacidade de extrair sentido do caos - transformar Big Data em Big Information.

Esse é o motivo pelo qual usamos documentos JSON estruturados, em vez de blobs amorfos de dados.
Elasticsearch não apenas armazena o documento, mas também indexa o conteúdo do documento para torná-lo pesquisável.

Cada campo em um documento é indexado e pode ser consultado. E não é só isso.
Durante uma única consulta, o Elasticsearch pode usar todos esses índices para retornar resultados

Embora muitas pesquisas funcionem apenas a toque de caixa, para usar o Elasticsearch em todo o seu potencial, você precisa entender três assuntos:

Mapeamento:
    Como os dados em cada campo são interpretados

Análise:
    Como o texto completo é processado para torná-lo pesquisável

Consultar DSL:
    A linguagem de consulta poderosa e flexível usada pelo Elasticsearch

--> Transformar em elasticSample.http: https://gist.github.com/clintongormley/8579281



Capítulo 5. Pesquisando - As ferramentas básicas
Até agora, aprendemos como usar o Elasticsearch como um armazenamento simples de documentos distribuídos no estilo NoSQL. Podemosjogue documentos JSON no Elasticsearch e recupere cada um por ID. Mas o verdadeiro poder do Elasticsearch está em sua capacidade de extrair sentido do caos - transformar Big Data em Big Information.

Esse é o motivo pelo qual usamos documentos JSON estruturados, em vez de blobs amorfos de dados. Elasticsearch não apenas armazena o documento, mas também indexa o conteúdo do documento para torná-lo pesquisável.

Cada campo em um documento é indexado e pode ser consultado .E não é só isso. Durante uma única consulta, o Elasticsearch pode usar todos esses índices para retornar resultados em uma velocidade de tirar o fôlego. Isso é algo que você nunca poderia considerar fazer com um banco de dados tradicional.

Uma pesquisa pode ser qualquer uma das seguintes:

Uma consulta estruturada em campos concretoscomo genderou age, classificado por um campo como join_date, semelhante ao tipo de consulta que você poderia construir em SQL

Uma consulta de texto completo, que encontra todos os documentos que correspondem às palavras-chave da pesquisa e os retorna classificados por relevância

Uma combinação dos dois

Embora muitas pesquisas funcionem apenas a partir de a caixa, para usar o Elasticsearch em todo o seu potencial, você precisa entender três assuntos:

Mapeamento
Como os dados em cada campo são interpretados

Análise
Como o texto completo é processado para torná-lo pesquisável

Consultar DSL
A linguagem de consulta poderosa e flexível usada pelo Elasticsearch

Cada um deles é um grande assunto por si só, e os explicamos em detalhes na Parte II . Os capítulos desta seção apresentam os conceitos básicos de todos os três - apenas o suficiente para ajudá-lo a obter uma compreensão geral de como a pesquisa funciona.

Começaremos explicando a searchAPI em sua forma mais simples.

DADOS DE TESTE
Os documentos que usaremos para fins de teste neste capítulo podem ser encontrados neste resumo: https://gist.github.com/clintongormley/8579281 .

Você pode copiar os comandos e colá-los em seu shell para acompanhar este capítulo.

Alternativamente, se você estiver na versão online deste livro, você pode clicar aqui para abrir no Sense ( sense_widget.html? Snippets / 050_Search / Test_data.json ).

------------------A Busca Vazia------------------

A forma mais básica da API de pesquisa é a pesquisa vazia, que não especifica nenhuma consulta, mas simplesmente retorna todos os documentos em todos os índices do cluster:

GET /_search

A seção mais importante da resposta é hits, quecontém o totalnúmero de documentos que corresponderam à
nossa consulta e uma hits matriz contendo os 10 primeiros desses documentos correspondentes - os resultados.

Cada elemento também tem um _score. Essa é a pontuação de relevância , que é uma medida de quão bem o documento corresponde à consulta.
São retornados primeiro com os documentos mais relevantes; ou seja, em ordem decrescente de _score;
O tookvalor nos diz quantos milissegundos toda a solicitação de pesquisa;


O timed_out valor diznos informa se a consulta expirou. Exemplo:

GET /_search?timeout=10ms


---------------Multi-índice, Multitipo-------------

Ao não limitar nossa pesquisa a um índice ou tipo específico, pesquisamos em todos os documentos do cluster. O Elasticsearch encaminhou a solicitação de pesquisa em
paralelo para um primário ou réplica de cada shard no cluster, reuniu os resultados para selecionar os 10 principais gerais e os retornou para nós.

Normalmente, no entanto, você vai desejar pesquisar em um ou mais índices específicos e provavelmente em um ou mais tipos específicos.
Podemos fazer isso especificando o índice e digitando a URL, da seguinte forma:


/_search
Pesquise todos os tipos em todos os índices

/gb/_search
Pesquisar todos os tipos no gbíndice

/gb,us/_search
Pesquise todos os tipos nos índices gbeus

/g*,u*/_search
Pesquise todos os tipos em qualquer índice começando com gou começando comu

/gb/user/_search
Tipo de pesquisa userno gbíndice

/gb,us/user,tweet/_search
Tipos de pesquisa usere tweetnos índices gbeus

/_all/user,tweet/_search
Tipos de pesquisa usere tweetem todos os índices

---------------Paginação---------------

Da mesma forma que o SQL usa a LIMIT palavra-chave para retornar uma única “página” de resultados, o Elasticsearch aceitaos parâmetros frome size:

Se você quiser mostrar cinco resultados por página, as páginas 1 a 3 podem ser solicitadas da seguinte forma:

GET /_search?size=5
GET /_search?size=5&from=5
GET /_search?size=5&from=10


Cuidado com a paginação muito profunda ou solicitando muitos resultados de uma só vez. Os resultados são classificados antes de serem retornados.
Mas lembre-se de que uma solicitação de pesquisa geralmente abrange vários fragmentos.
Cada fragmento gera seus próprios resultados classificados, que precisam ser classificados centralmente para garantir que a ordem geral esteja correta.

DEEP PAGING EM SISTEMAS DISTRIBUÍDOS
Para entender porque a paginação profunda é problemática, vamos imaginar que estamos pesquisando em um único índice com cinco fragmentos primários.
Quando solicitamos a primeira página de resultados (resultados de 1 a 10), cada fragmento produz seus próprios 10 principais resultados e os retorna ao nó solicitante ,
que classifica todos os 50 resultados para selecionar os 10 principais gerais.

Agora imagine que pedimos a página 1.000 – resultados de 10.001 a 10.010. Tudo funciona da mesma maneira, exceto que cada fragmento deve produzir seus 10.010 principais resultados.
O nó solicitante então classifica todos os 50.050 resultados e descarta 50.040 deles!

Você pode ver que, em um sistema distribuído, o custo da classificação dos resultados cresce exponencialmente quanto mais aprofundamos a paginação.
Há uma boa razão para que os mecanismos de pesquisa na web não retornem mais de 1.000 resultados para qualquer consulta.


---------------Pesquisa Lite---------------
Quando você indexa um documento, o Elasticsearch pega os valores de string de todos os seus campos e os concatena em uma grande string,
que ele indexa como o _allcampo especial.Por exemplo, quando indexamos este documento:

{
    "tweet":    "However did I manage before Elasticsearch?",
    "date":     "2014-09-14",
    "name":     "Mary Jones",
    "user_id":  1
}
é como se tivéssemos adicionado um campo extra chamado _allcom este valor:

"However did I manage before Elasticsearch? 2014-09-14 Mary Jones 1"
A pesquisa de string de consulta usa o _allcampo, a menos que outro nome de campo tenha sido especificado.

---------Consultas mais complicadas-------------


A próxima consulta procura tweets, usando os seguintes critérios:

O namecampo contém mary ou john

O date é maior que 2014-09-10

O _allcampo contém uma das palavras aggregations ou geo

GET http://localhost:9200/_search?q=%2Bname%3A(mary+john)+%2Bdate%3A%3E2014-09-10+%2B(aggregations+geo)

Como você pode ver nos exemplos anteriores, essa pesquisa de string de consulta lite é surpreendentemente poderosa.Sua sintaxe de consulta,
que é explicada em detalhes nos documentos de referência de sintaxe de string de consulta ,
nos permite expressar consultas bastante complexas de forma sucinta. Isso o torna ótimo para consultas descartáveis da linha de comando ou durante o desenvolvimento.

Por fim, a pesquisa de string de consulta permite que qualquer usuário execute consultas potencialmente lentas e pesadas em qualquer campo em seu índice,
possivelmente expondo informações privadas ou até mesmo deixando seu cluster de joelhos!

DICA
Por esses motivos, não recomendamos a exposição de pesquisas de string de consulta diretamente a seus usuários, a menos que sejam usuários avançados aos quais possa confiar seus dados e seu cluster.


-------------Capítulo 6. Mapeamento e Análise----------------


Enquanto brincamos com os dados em nosso índice, notamos algo estranho. Algo parece estar quebrado: temos 12 tweets em nossos índices, e apenas um deles contém a data 2014-09-15, mas dê uma olhada nos totalhits para as seguintes consultas:

GET /_search?q=2014              # 12 results
GET /_search?q=2014-09-15        # 12 results !
GET /_search?q=date:2014-09-15   # 1  result
GET /_search?q=date:2014         # 0  results !


O Elasticsearch gerou um mapeamento dinamicamente para nós, com base no que ele poderia adivinhar sobre nossos tipos de campo.
A resposta nos mostra que o datecampo foi reconhecido como um campo do tipo date.
O _allcampo não é mencionado porque é um campo padrão, mas sabemos que o _allcampo é do tipo string.

Mas, de longe, a maior diferença é entre os camposque representam valores exatos (que podem incluir stringcampos) e campos que representam texto completo.
Essa distinção é realmente importante - é o que separa um mecanismo de pesquisa de todos os outros bancos de dados.

-------------Valores exatos versus texto completo----------------

Os dados no Elasticsearch podem ser divididos em dois tipos: valores exatos e texto completo.

Os valores exatos são exatamente o que parecem. Os exemplos são uma data ou um ID de usuário,
mas também podem incluir strings exatas, como um nome de usuário ou um endereço de e-mail.
O valor exato "Foo" não é o mesmo que o valor exato "foo". O valor exato 2014 não é o mesmo que o valor exato 2014-09-15.

O texto completo, por outro lado, refere-sea dados textuais – geralmente escritos em alguma linguagem humana – como o texto de um tweet ou o corpo de um e-mail.


Os valores exatos são fáceis de consultar. A decisão é binária; um valor corresponde à consulta ou não. Esse tipo de consulta é fácil de expressar com SQL:

WHERE name    = "John Smith"
  AND user_id = 2
  AND date    > "2014-09-15"

Consultar dados de texto completo é muito mais sutil.
Não estamos apenas perguntando: “Este documento corresponde à consulta”, mas “Quão bem este documento corresponde à consulta?”
Em outras palavras, quão relevante é este documento para a consulta dada?

Raramente queremos corresponder exatamente todo o campo de texto completo. Em vez disso, queremos pesquisar nos campos de texto.
Não apenas isso, mas esperamos que a pesquisa entenda nossa intenção :


Uma pesquisa por UK também deve retornar documentos que mencionem o United Kingdom.

Uma pesquisa por jump também deve corresponder a jumped, jumps, jumpinge talvez até leap.

johnny walker deve corresponder Johnnie Walker, e johnnie depp deve corresponder Johnny Depp.

Fox news hunting deve retornar notícias sobre caça na Fox News, enquanto fox hunting news deve retornar notícias sobre caça à raposa.

Para facilitar esses tipos de consultas em campos de texto completo, o Elasticsearch primeiro analisa o texto e, em seguida, usa os resultados para criar um índice invertido

------------Capítulo 6. Mapeamento e Análise------------

Enquanto brincamos com os dados em nosso índice, notamos algo estranho.
Algo parece estar quebrado: temos 12 tweets em nossos índices, e apenas um deles contém a data 2014-09-15, mas dê uma olhada nos total hits para as seguintes consultas:

GET /_search?q=2014              # 12 results
GET /_search?q=2014-09-15        # 12 results !
GET /_search?q=date:2014-09-15   # 1  result
GET /_search?q=date:2014         # 0  results !

Mas, de longe, a maior diferença é entre os campos que representam valores exatos (que podem incluir string campos)
e campos que representam texto completo.
Essa distinção é realmente importante - é o que separa um mecanismo de pesquisa de todos os outros bancos de dados.

--------------Valores exatos versus texto completo-------------------------

Os dados no Elasticsearch podem ser divididos em dois tipos: valores exatos e texto completo.

Os valores exatos são exatamente o que parecem. Os exemplos são uma data ou um ID de usuário, mas também podem incluir strings exatas, como um nome de usuário ou um
endereço de e-mail. O valor exato Foonão é o mesmo que o valor exato foo. O valor exato 2014não é o mesmo que o valor exato 2014-09-15.

O texto completo, por outro lado, refere-sea dados textuais – geralmente escritos em alguma linguagem humana – como o texto de um tweet ou o corpo de um e-mail.

O texto completo é muitas vezes referido como dados não estruturados, que é um nome impróprio —
a linguagem natural é altamente estruturada. O problema é que as regras das linguagens naturais são complexas, o que as torna difíceis para os computadores analisarem corretamente.
Por exemplo, considere esta frase:

"Maio é divertido, mas junho me aborrece."

Refere-se a meses ou a pessoas?

Os valores exatos são fáceis de consultar. A decisão é binária; um valor corresponde à consulta ou não. Esse tipo de consulta é fácil de expressar com SQL:

WHERE name    = "John Smith"
  AND user_id = 2
  AND date    > "2014-09-15"


Consultar dados de texto completo é muito mais sutil.
Não estamos apenas perguntando: “Este documento corresponde à consulta”, mas “Quão bem este documento corresponde à consulta?”
Em outras palavras, quão relevante é este documento para a consulta dada?

Raramente queremos corresponder exatamente todo o campo de texto completo. Em vez disso, queremos pesquisar nos campos de texto. Não apenas isso, mas esperamos que a pesquisa entenda nossa intenção:

Uma pesquisa por UK também deve retornar documentos que mencionem o United Kingdom.

Uma pesquisa por jump também deve corresponder a jumped, jumps, jumpinge talvez até leap.

johnny walkerdeve corresponder Johnnie Walker, e johnnie depp deve corresponder Johnny Depp.

fox news hunting deve retornar notícias sobre caça na Fox News, enquanto fox hunting news deve retornar notícias sobre caça à raposa.

Para facilitar esses tipos de consultas em campos de texto completo, o Elasticsearch primeiro analisa o texto e, em seguida, usa os resultados para criar um índice invertido


---------------Índice invertido----------------------

O Elasticsearch usa uma estrutura chamadaum índice invertido , projetado para permitir pesquisas de texto completo muito rápidas.
Um índice invertido consiste em uma lista de todas as palavras únicas que aparecem em qualquer documento e, para cada palavra, uma lista dos documentos em que ela aparece.

Por exemplo, digamos que temos dois documentos, cada um com um contentcampo contendo o seguinte:

- A ligeira raposa marrom saltou sobre o cão preguiçoso

- Raposas marrons rápidas saltam sobre cães preguiçosos no verão

Content campo de cada documento emwords (que chamamos de termos , ou tokens ), crie uma lista ordenada de todos os termos exclusivos e, em seguida, liste em qual documento cada termo aparece.

Termo Doc_1 Doc_2
-------------------------
Rápido | | X
O | X |
marrom | X | X
cão | X |
cães | | X
raposa | X |
raposas | | X
em | | X
saltou | X |
preguiçoso | X | X
salto | | X
sobre | X | X
rápido | X |
verão | | X
o | X |
------------------------

Agora, se quisermos pesquisar por Rápido marrom, basta encontrar os documentos em que cada termo aparece:

Termo Doc_1 Doc_2
-------------------------
marrom | X | X
rápido | X |
------------------------
Total | 2 | 1

Ambos os documentos correspondem, mas o primeiro documento tem mais correspondências do que o segundo.
Se aplicarmos um algoritmo de similaridade ingênuo que apenas conta o número de termos correspondentes,
então podemos dizer que o primeiro documento é uma correspondência melhor - é mais relevante para nossa consulta - do que o segundo documento.

Mas existem alguns problemas com nosso índice invertido atual:

Rápido rápido aparecem como termos separados, enquanto o usuário provavelmente pensa neles como a mesma palavra.

raposa e raposas são bastante semelhantes, assim como cão e cães;Eles compartilham a mesma palavra raiz.

saltou e pulo, embora não sejam da mesma palavra raiz, são semelhantes em significado. São sinônimos.

Se normalizarmos os termos em um padrãoformato, podemos encontrar documentos que contêm termos que não são exatamente os mesmos que o usuário solicitou,
mas são semelhantes o suficiente para ainda serem relevantes. Por exemplo:

"Rápido" pode ser minúsculo para se tornar "rápido".

raposas espode ser desmembrado --reduzido à sua forma raiz- para se tornar raposa. Da mesma forma, cachoros poderia ser derivado de cachoro.

salto e pulo são sinônimos e podem ser indexados como um único termo salto.


Termo Doc_1 Doc_2
-------------------------
marrom | X | X
cão | X | X
raposa | X | X
em | | X
salto | X | X
preguiçoso | X | X
sobre | X | X
rápido | X | X
verão | | X
o | X | X
------------------------

Mas ainda não chegamos lá. Nossa busca por ainda+ rapidos +raposas falharia, porque não temos mais o termo exato em nosso índice.
No entanto, se aplicarmos as mesmas regras de normalização que usamos no campo para nossa string de consulta, ela se tornaria uma consulta para , que corresponderia a ambos os documentos!


-------------------------------Tipos de campo simples principais------------------------------
Fragmento:string

Número inteiro: byte, short, integer,long

Ponto flutuante: float,double

Boleano:boolean

Encontro:date


-------------------------------Personalizando mapeamentos de campo------------------------------

Enquanto os tipos de dados de campo básicos sãosuficiente para muitos casos,
muitas vezes você precisará personalizar o mapeamentopara campos individuais,
especialmente campos de string. Os mapeamentos personalizados permitem que você faça o seguinte:

Distinguir entre campos de string de texto completo e campos de string de valor exato

Use analisadores específicos de idioma

Otimizar um campo para correspondência parcial

Especificar formatos de data personalizados


O atributo mais importante de um campo é o type.
Para campos que não sejam stringcampos, você raramente precisará mapear algo além de type:

Os campos de tipo stringsão, por padrão, considerados como contendo texto completo.
Ou seja, seu valor será repassadoum analisador antes de ser indexado
e uma consulta de texto completo no campo passará a string de consulta por um analisador antes de pesquisar.

O valor padrão de indexpara um stringcampo é analyzed. Se quisermos mapear o campo como um valor exato, precisamos defini-lo como not_analyzed:

{
    "tag": {
        "type":     "string",
        "index":    "not_analyzed"
    }
}

Os outros tipos simples (como long, double, dateetc) também aceitam o indexparâmetro,
mas os únicos valores relevantes são noe not_analyzed, pois seus valores nunca são analisados.


------------------analisador--------------------


Para analyzedcampos de string, useo analyzeratributo para especificar qual analisador aplicar no momento da pesquisa e no momento do índice.
Por padrão, o Elasticsearch usa o standardanalisador, mas você pode alterar isso especificando um dos analisadores integrados, como whitespace, simple ou english

----------------Atualizando um mapeamento--------------------

Você pode especificar o mapeamento para um tipo quando você criar um índice.
Como alternativa, você pode adicionar o mapeamento para um novo tipo (ou atualizar o mapeamento para um tipo existente) posteriormente,
usando o ponto de /_mapping extremidade.

Embora você possa adicionar a um mapeamento existente, não pode alterá -lo. Se já existir um campo no mapeamento, os dados desse campo provavelmente já foram indexados. ]
Se você alterar o mapeamento de campo, os dados já indexados estarão errados e não poderão ser pesquisados adequadamente.

------------------------Tipos de campos principais complexos-----------------

Além dos tipos de dados escalares simples que mencionamos,
JSON também tem null valores, matrizes e objetos, todos suportados pelo Elasticsearch.

-------------------Campos de vários valores----------------------------------

Obs:

O _sourcecampo que você recebe de volta contém exatamente o mesmo documento JSON que você indexou.

Matrizes:

Não há mapeamento especial necessário para matrizes.Qualquer campo pode conter zero, um ou mais valores,
da mesma forma que um campo de texto completo é analisado para produzir vários termos.

No entanto, os arrays são indexados — tornados pesquisáveis
como campos de vários valores, que não são ordenados.No momento da pesquisa, você não pode se referir
a “o primeiro elemento” ou “o último elemento”. Em vez disso, pense em uma matriz como um pacote de valores.

--------------Objetos de vários níveis----------------------------


O Elasticsearch detectará novos campos de objeto
dinamicamente e mapeie-os como type object, com cada campo interno listado em properties:

No mapeamento fica algo como:

{
  "gb": {
    "tweet": { 1
      "properties": {
        "tweet":            { "type": "string" },
        "user": { 2
          "type":             "object",
          "properties": {
            "id":           { "type": "string" },
            "gender":       { "type": "string" },
            "age":          { "type": "long"   },
            "name":   { 2
              "type":         "object",
              "properties": {
                "full":     { "type": "string" },
                "first":    { "type": "string" },
                "last":     { "type": "string" }
              }
            }
          }
        }
      }
    }
  }
}

--------------Como os objetos internos são indexados------------

Lucene não entende objetos internos.Um documento Lucene consiste em uma lista simples de pares chave-valor.
Para que o Elasticsearch indexe objetos internos de maneira útil, ele converte nosso documento em algo assim:

{
    "tweet":            [elasticsearch, flexible, very],
    "user.id":          [@johnsmith],
    "user.gender":      [male],
    "user.age":         [26],
    "user.name.full":   [john, smith],
    "user.name.first":  [john],
    "user.name.last":   [smith]
}

No documento simplificado simples anterior, não há nenhum campo chamado user e nenhum campo chamado user.name.
O Lucene indexa apenas valores escalares ou simples, não estruturas de dados complexas.

-------------------------Matrizes de objetos internos---------------

Finalmente, considere como um array contendo objetos internos seriam indexados. Digamos que temos uma followers matriz que se parece com isso:

{
    "followers": [
        { "age": 35, "name": "Mary White"},
        { "age": 26, "name": "Alex Jones"},
        { "age": 19, "name": "Lisa Smith"}
    ]
}

Este documento será achatado como descrevemos anteriormente, mas o resultado ficará assim:

{
    "followers.age":    [19, 26, 35],
    "followers.name":   [alex, jones, lisa, smith, mary, white]
}

A correlação entre {age: 35}e {name: Mary White}foi perdida, pois cada campo de vários valores é apenas um pacote de valores, não uma matriz ordenada.
Isso é suficiente para perguntarmos: “Existe algum seguidor com 26 anos?”

Mas não podemos obter uma resposta precisa para isso: “Existe um seguidor que tem 26 anos e que se chama Alex Jones ?”


----------Capítulo 7. Pesquisa de corpo inteiro--------------------

Os autores do Elasticsearch preferem usar GET para uma solicitação de pesquisa porque acham que descreve a ação — recuperar informações — melhor do que o POST verbo.
No entanto, como GET um corpo de solicitação não é universalmente compatível, a searchAPI também aceita POST pedidos:

POST /_search
{
  "from": 30,
  "size": 10
}

----------------Consulta DSL-----------------------------------

A consulta DSL é uma pesquisa flexível e expressiva linguagem que o Elasticsearch usa para expor a maior parte do poder do Lucene por meio de uma interface JSON simples.
É o que você deve usar para escrever suas consultas em produção. Isso torna suas consultas mais flexíveis, mais precisas, mais fáceis de ler e mais fáceis de depurar.

Para usar o Query DSL, passe uma query no query parâmetro:

GET /_search
{
    "query": {
        "match_all": {}
    }
}

-------------------Estrutura de uma Cláusula de Consulta------------

Uma cláusula de consulta normalmentetem esta estrutura:

{
    QUERY_NAME: {
        ARGUMENT: VALUE,
        ARGUMENT: VALUE,...
    }
}

Se fizer referência a um campo específico, terá esta estrutura:

{
    QUERY_NAME: {
        FIELD_NAME: {
            ARGUMENT: VALUE,
            ARGUMENT: VALUE,...
        }
    }
}

A solicitação de pesquisa completa ficaria assim:

GET /_search
{
    "query": {
        "match": {
            "tweet": "elasticsearch"
        }
    }
}

--------------------Combinando várias cláusulas-----------------------------

Cláusulas de consulta são blocos de construção simplesque podem ser combinados entre si para criar consultas complexas. As cláusulas podem ser as seguintes:

Cláusulas folha (como a matchcláusula) quesão usados para comparar um campo (ou campos) com uma string de consulta.

Cláusulas compostas que são usadas para combinar outras cláusulas de consulta.
Por exemplo, uma bool cláusula permite combinar outras cláusulas que must correspondam, must_not correspondam ou should correspondam, se possível:

{
    "bool": {
        "must":     { "match": { "tweet": "elasticsearch" }},
        "must_not": { "match": { "name":  "mary" }},
        "should":   { "match": { "tweet": "full text" }}
    }
}

-------------------Consultas e filtros-------------------------------------

Embora nos refiramos à DSL de consulta, na realidade existem duas DSLs: a DSL de consulta e a DSL de filtro

Um filtro faz uma pergunta sim|não decada documento e é usado para campos que contêm valores exatos

Uma consulta é semelhante a um filtro, mas também solicita a pergunta: Quão bem este documento corresponde?

Uma consulta calcula a relevância de cada documentoé para a consulta e atribui a ela uma relevância _score,
que é usada posteriormente para classificar os documentos correspondentes por relevância.
Esse conceito de relevância é bem adequado para pesquisa de texto completo, onde raramente há uma resposta completamente “correta”.

--------------Diferenças de desempenho--------------------------------

A saída da maioria das cláusulas de filtro - um simpleslista dos documentos que correspondem ao filtro é rápido de calcular e fácil de armazenar em cache na memória,
usando apenas 1 bit por documento. Esses filtros em cache podem ser reutilizados com eficiência para solicitações subsequentes.

As consultas precisam não apenas encontrar documentos correspondentes, mas também calculam a relevância de cada documento,
o que normalmente torna as consultas mais pesadas do que os filtros. Além disso, os resultados da consulta não podem ser armazenados em cache.

Graças ao índice invertido, uma consulta simples que corresponde a apenas alguns documentos pode ter um desempenho tão bom ou melhor do que um filtro em cache que abrange milhões de documentos.
Em geral, no entanto, um filtro em cache superará uma consulta e o fará de forma consistente.

O objetivo dos filtros é reduzir o número de documentos que precisam ser examinados pela consulta.

Quando usar qual

Como regra geral, use cláusulas de consulta para pesquisa de texto completo ou para
qualquer condição que deva afetar a pontuação de relevância e use cláusulas de filtro para todo o resto.

--------------------Filtro de termo-------------------------------------

O term filtro é usado para filtrar porvalores exatos, sejam eles números, datas, booleanos ou not_analyzed campos de string de valor exato

{ "term": { "age":    26           }}
{ "term": { "date":   "2014-09-01" }}
{ "term": { "public": true         }}
{ "term": { "tag":    "full_text"  }}



