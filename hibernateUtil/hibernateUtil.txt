One to many --> 
- sempre utilizar Lazy nas duas pontas;
- criar métodos auxiliares exemplo algo como:
@OneToMany (cascade = CascadeType.ALL, orphaRemove=true)

 public void addBook (livro livro) {
        this.books.add (livro);
        book.setAuthor (this);
    }
    public void removeBook (livro livro) {
        book.setAuthor (null);
        this.books.remove (livro);
    }
    public void removeBooks () {
        Iterator <Book> iterator = this.books.iterator ();
        while (iterator.hasNext ()) {
            Livro livro = iterator.next ();
            book.setAuthor (null);
            iterator.remove ();
        }
    }

- Sempre cascadeAll
- Utilizar dessa forma pq é melhor mais performatico e menos trabalho na manutenção que outros uniderecional
ou com tabela auxiliar;

---------------------------------
-ManyToMany --> 
- A associação @ManyToMany bidirecional pode ser navegada de ambos os lados, portanto, ambos os lados podem ser pais (lado dos pais). Como ambos são pais, nenhum deles terá uma chave estrangeira. Nessa associação, há duas chaves estrangeiras armazenadas em uma tabela separada, conhecida como junção ou tabela de junção. A mesa de junção está oculta e desempenha o papel do lado da criança.
-Sempre utilizar set em vez de list, muito melhor na remoção, evita comandos sqls a mais para fazer o delete;
-Evitar cascadeType.ALL e CascadeType.REMOVE;
-Usar o mapeamento @ManyToMany padrão requer que o desenvolvedor escolha um proprietário do relacionamento e um lado mappedBy (também conhecido como o lado inverso). Apenas um lado pode ser o proprietário e as alterações são propagadas para o banco de dados apenas deste lado específico.
-Na maioria dos casos, remoções em cascata são ideias ruins. Por exemplo, a remoção de uma entidade Autor não deve desencadear a remoção de um Livro porque o Livro também pode ser referenciado por outros autores (um livro pode ser escrito por vários autores). Portanto, evite CascadeType.ALL e CascadeType.REMOVE e dependem explícita CascadeType.PERSIST e CascadeType.MERGE:
-
A remoção de uma entidade Autor é automaticamente enviada em cascata às entidades Book associadas . Isso está acontecendo enquanto CascadeType.REMOVE ou órfãoRemoval = true estiver presente. Ou seja, nessa perspectiva, a presença.

Então, como eles são diferentes? Bem, considere o seguinte método auxiliar usado para desconectar (ou desassociar) um livro de seu autor :
public void removeBook (livro livro) {
    book.setAuthor (null);
    this.books.remove (livro);
}
Ou, para desconectar todos os livros de seus autores :
public void removeBooks () {
Iterator <Book> iterator = this.books.iterator ();
    while (iterator.hasNext ()) {
        Livro livro = iterator.next ();
        book.setAuthor (null);
        iterator.remove ();
    }
}
Chamar o método removeBook () na presença de órfãoRemoval = true resultará na remoção automática do livro por meio de uma instrução DELETE . Chamá-lo na presença de órfãoRemoval = false acionará uma instrução UPDATE . Como desconectar um livro não é uma operação de remoção, a presença de CascadeType.REMOVE não importa. Portanto, órfãoRemoval = true é útil para limpar entidades (remover referências pendentes) que não deveriam existir sem uma referência de uma entidade proprietária ( Autor ).


----Exclusão em massa ManyToMany:

Um autor já foi carregado no contexto de persistência
Vamos supor que o Autor que deve ser excluído foi carregado anteriormente no Contexto de Persistência sem seu Livro associado . Para excluir este Autor e os livros associados, você pode usar o identificador de autor ( author.getId () ). Primeiro, exclua todos os livros associados do autor:
// adicione este método em BookRepository
@Transactional
@Modifying (flushAutomatically = true, clearAutomatically = true)
@Query ("DELETE FROM Book b WHERE b.author.id =? 1")
public int deleteByAuthorIdentifier (Long id);
Então, vamos deletar o autor por seu identificador:
// adicione este método em AuthorRepository
@Transactional
@Modifying (flushAutomatically = true, clearAutomatically = true)
@Query ("DELETE FROM Author a WHERE a.id =? 1")
public int deleteByIdentifier (Long id);
A presença de flushAutomatically = true, clearAutomatically = true é explicada um pouco mais tarde. Por enquanto, o método de serviço responsável por acionar a exclusão é:
@Transactional
public void deleteViaIdentifiers () {
    Autor autor = autorRepositório.findByName ("Joana Nimar");
    bookRepository.deleteByAuthorIdentifier (author.getId ());
    authorRepository.deleteByIdentifier (author.getId ());
}
Chamar deleteViaIdentifiers () aciona as seguintes consultas:
APAGAR DO livro
WHERE author_id =?
EXCLUIR DO autor
ONDE id =?
Observe que os livros associados não são carregados no Contexto de Persistência e há apenas duas instruções DELETE acionadas. O número de livros não afeta o número de instruções DELETE .
O autor também pode ser excluído por meio do deleteInBatch integrado (entidades Iterable <T>) :
authorRepository.deleteInBatch (List.of (autor));
Mais autores foram carregados no contexto de persistência
Vamos supor que o Contexto de Persistência contém mais Author s que devem ser excluídos. Por exemplo, vamos deletar todos os autores de 34 anos buscados como uma Lista <Autor> (vamos supor que há dois autores de 34 anos ). Tentar excluir por identificador de autor (como no caso anterior) resultará em EXCLUIR separadamente para cada autor. Além disso, haverá um DELETE separado para os livros associados de cada autor. Portanto, isso não é eficiente.
Desta vez, vamos contar com duas operações em massa . Um definido por você por meio do operador IN (que permite especificar vários valores em uma cláusula WHERE ) e o deleteInBatch integrado (entidades Iterable <T>) :
// adicione este método em BookRepository
@Transactional
@Modifying (flushAutomatically = true, clearAutomatically = true)
@Query ("DELETE FROM Book b WHERE b.author IN? 1")
public int deleteBulkByAuthors (Listar <Author> autores);
Os métodos de serviço para excluir uma Lista <Author> e o Livro associado são os seguintes:
@Transactional
public void deleteViaBulkIn () {
    Listar <Autor> autores = autorRepositório.findByAge (34);
    bookRepository.deleteBulkByAuthors (autores);
    authorRepository.deleteInBatch (autores);
}
Chamar deleteViaBulkIn () aciona as seguintes consultas:
APAGAR DO livro
ONDE author_id IN (?,?)
EXCLUIR DO autor
ONDE id =?
  OR id =?
Observe que os livros associados não são carregados no Contexto de Persistência e há apenas duas instruções DELETE acionadas. O número de autores e livros não afeta o número de declarações DELETE .



Item 7: Como buscar associações por meio de gráficos de entidades JPA -->


Definindo um gráfico de entidade via @NamedEntityGraph
A anotação @NamedEntityGraph ocorre no nível da entidade. Por meio de seus elementos, o desenvolvedor pode especificar um nome exclusivo para este gráfico de entidade (por meio do elemento de nome ) e os atributos a serem incluídos ao buscar o gráfico de entidade (por meio do elemento attributeNodes , que contém uma lista de anotações @NamedAttributeNode separadas por vírgulas; cada @NamedAttributeNode desta lista corresponde a um campo / associação que deve ser buscado). Os atributos podem ser campos básicos e associações.
Vamos colocar o gráfico da entidade em código na entidade Autor :
@Entidade
@NamedEntityGraph (
    nome = "autor-livros-gráfico",
    attributeNodes = {
        @NamedAttributeNode ("livros")
    }
)
public class Author implementa Serializable {
    privado estático final longo serialVersionUID = 1L;
    @Identidade
    @GeneratedValue (strategy = GenerationType.IDENTITY)
    ID longa privada;
    nome da string privada;
    gênero particular String;
    idade privada;
    @OneToMany (cascade = CascadeType.ALL,
             mappedBy = "autor", órfãoRemoval = verdadeiro)
      Lista privada <Book> books = new ArrayList <> ();
    // getters e setters omitidos por questões de brevidade
}
Em seguida, concentre-se no repositório da entidade Autor , AuthorRepository .
O AuthorRepository é o local onde o gráfico da entidade deve ser especificado. Spring Data fornece suporte para gráficos de entidade por meio da anotação @EntityGraph (a classe dessa anotação é org.springframework.data.jpa.repository.EntityGraph ).
Substituindo um Método de Consulta
Por exemplo, o código para usar o gráfico de entidade ( author-books-graph ) para encontrar todos os Author s, incluindo o Book associado , é o seguinte ( EntityGraph.EntityGraphType.FETCH é o padrão e indica um gráfico de busca; EntityGraph.EntityGraphType. LOAD pode ser especificado para um gráfico de carga):
@Repositório
@Transactional (readOnly = true)
interface pública AuthorRepository estende JpaRepository <Author, Long> {
    @Sobrepor
    @EntityGraph (value = "author-books-graph",
                type = EntityGraph.EntityGraphType.FETCH)
    Lista pública <Author> findAll ();
}


------------------Entidades:

Você pode buscar uma entidade por identificador por meio dos métodos de consulta integrados do Spring, findById () ou getOne () . Por trás do método findById () , Spring usa EntityManager # find () , e por trás do método getOne () , Spring usa EntityManager # getReference () .

-----------------One-To-One maps id

O @MapsId é um 2,0 anotação APP que pode ser aplicado a @ManyToOne e unidireccionais (ou bidireccionais) @OneToOne associações . Por meio dessa anotação, a chave primária da tabela do livro também pode ser uma chave estrangeira que faz referência à chave primária da tabela do autor .

Existem várias vantagens em usar @MapsId , como segue:
Se o livro estiver presente no cache de segundo nível, ele será obtido de acordo (nenhuma viagem de ida e volta do banco de dados extra é necessária). Esta é a principal desvantagem de um @OneToOne unidirecional regular .
Buscar o autor não dispara automaticamente uma consulta adicional desnecessária para buscar o livro também. Esta é a principal desvantagem de um @OneToOne bidirecional regular .
Compartilhar a chave primária reduz a área de cobertura da memória (não há necessidade de indexar a chave primária e a chave estrangeira).

---Como validar que apenas uma associação é não nula

Exemplo:

class test{
@ManyToOne (fetch = FetchType.LAZY)...
@ManyToOne (fetch = FetchType.LAZY)...
@ManyToOne (fetch = FetchType.LAZY)...
}

Para garantir que pelo menos uma entidade seja preenchida basta adicionar o
@JustOneOfMany

-----------------------------------Assync-------------------------------------------------------------------



Durante a execução assíncrona:
- Use um manipulador de eventos assíncronos com AFTER_COMPLETION (ou suas especializações) se precisar executar qualquer tarefa que se encaixe bem na execução assíncrona.
- Se essas tarefas não envolverem operações de banco de dados (leitura / gravação), não use @Transactional no nível do método do manipulador de eventos (não inicie uma nova transação).
- Se essas tarefas envolverem operações de leitura e / ou gravação do banco de dados , use Propagation.REQUIRES_NEW e atrase a aquisição da conexão do banco de dados até que seja necessária (depois que a conexão do banco de dados for aberta, evite tarefas demoradas).
- Se essas tarefas envolverem apenas operações de leitura de banco de dados, anote o método do manipulador de eventos com @Transactional (readOnly = true, Propagation.REQUIRES_NEW) .
- Se essas tarefas envolverem operações de gravação de banco de dados , anote o método do manipulador de eventos com @Transactional (Propagation.REQUIRES_NEW) .
- Evite executar tarefas assíncronas na fase BEFORE_COMMIT , pois você não terá uma garantia de que essas tarefas serão concluídas antes que a transação do produtor seja confirmada.
- Dependendo do seu cenário, pode ser necessário interceptar a conclusão do thread do manipulador de eventos.


-------batch-------------------------------------------------------------------------------------------------
- rewriteBatchedStatements 

Depois que essa propriedade é habilitada, as instruções SQL são reescritas em um único buffer de string e enviadas em uma única solicitação ao banco de dados. Caso contrário, as instruções em lote (por exemplo, INSERT s) têm a seguinte aparência:
inserir valores de autor (idade, gênero, nome, id) (828, 'Gênero_810', 'Nome_810', 810)
inserir valores de autor (idade, gênero, nome, id) (829, 'Gênero_811', 'Nome_811', 811)
...
Com essa configuração, essas instruções SQL são reescritas da seguinte maneira:
inserir nos valores do autor (idade, gênero, nome, id) (828, 'Gênero_810', 'Nome_810', 810), (829, 'Gênero_811', 'Nome_811', 811), ...

- saveAll não é um método muito bom a ser utilizado;

-------------------------------------ElementCollection--------------

Especialmente ao definir uma associação unidirecional um-para-muitos para um tipo Básico (por exemplo, String ) ou tipo Embeddable JPA tem uma solução simples na forma de @ElementCollection .
Esses tipos são mapeados em uma tabela separada que pode ser personalizada por meio de @CollectionTable .

Observe que @ElementCollection não é um tipo de associação de entidade, mesmo que você possa pensar assim. Principalmente, como você verá no próximo item, @ElementCollection atua como um @OneToMany unidirecional ( Item 2 ). Portanto, ele sofre as mesmas penalidades de desempenho. As melhores práticas aconselham você a usar @ElementCollection para representar tipos básicos (por exemplo, inteiros ou strings) ou tipos incorporáveis, mas não classes de entidade.


Uma coleção que precisa ser atualizada frequentemente leva a óbvias penalidades de desempenho. É melhor confiar em uma associação explícita de um para muitos. Por outro lado, uma coleção que precisa de poucas (ou nenhuma) atualização é uma boa candidata para @ElementCollection , uma vez que não representa um lado da chave estrangeira.


------------------conexoes e transações--------------

Por que @Transactional foi ignorado? Existem duas razões principais :
@Transactional foi adicionado a um método privado , protegido ou protegido por pacote .
@Transactional foi adicionado a um método definido na mesma classe de onde é chamado.
Portanto, como regra geral, @Transactional funciona apenas em métodos públicos , e o método deve ser adicionado em uma classe diferente de onde é chamado.

Portanto, recomendamos o uso de @Transactional (readOnly = true) para métodos de consulta também, que você pode obter facilmente adicionando essa anotação à interface do repositório. Certifique-se de adicionar um @Transactional simples aos métodos de manipulação que você pode ter declarado ou redecorado naquela interface.

Portanto, garantimos que todos os métodos de consulta estão sendo executados em um contexto transacional somente leitura , anotando a interface do repositório com @Transactional (readOnly = true) . Além disso, para consulta-métodos que podem modificar dados, mudar para um transacional ao contexto que permite modificações de dados, adicionando @Transactional sem readOnly bandeira. Principalmente, o que fizemos aqui é exatamente o que Spring Data faz internamente para seus métodos de consulta integrados.


Como regra geral, se esforce para evitar transações que intercalam lógicas de negócios pesadas que não interagem com o banco de dados com invocações de método de consulta. Isso pode resultar em transações demoradas e métodos de serviço complexos que se tornam demorados e difíceis de entender, depurar, refatorar e revisar. Quase sempre há soluções melhores, apenas leve o seu tempo para encontrá-las.


Anote as interfaces do repositório com @Transactional (readOnly = true) .

Substitua @Transactional (readOnly = true) por @Transactional para métodos de consulta que modificam dados / geram DML (como INSERT , UPDATE e DELETE ).

Atrasar aquisição de conexão de banco de dados:
Para o Hibernate 5.2.10+, atrase a aquisição da conexão do banco de dados até que seja realmente necessário (consulte o item 60 ).
Avalie cada método de serviço:
Avalie cada método de serviço para decidir se deve ser anotado com @Transactional ou não.

Se você decidir anotar um método de serviço com @Transactional , adicione o @Transactional adequado . Você deve adicionar @Transactional (readOnly = true) se chamar apenas métodos de consulta somente leitura e adicionar @Transactional se chamar pelo menos um método de consulta que pode modificar dados.

Meça e monitore a duração da transação:
Certifique-se de avaliar a duração da transação e o comportamento no contexto do mecanismo de propagação da transação atual ( Apêndice G ) e se esforce para transações curtas e curtas / rápidas.

Depois que a conexão com o banco de dados é adquirida, ela permanece aberta até que a transação seja concluída. Portanto, projete suas soluções para evitar transações demoradas.

Evite adicionar @Transactional no nível da classe do controlador ou no nível da classe de serviço, pois isso pode levar a transações de longa duração ou mesmo desnecessárias (tal classe é propensa a abrir contextos transacionais e adquire conexões de banco de dados para métodos que não necessidade de interagir com o banco de dados). 
Por exemplo, um desenvolvedor pode adicionar métodos públicos que contêm lógica de negócios que não interage com o banco de dados; nesses casos, se você atrasar a aquisição da conexão com o banco de dados, o Spring Boot ainda preparará o contexto transacional, mas nunca adquirirá uma conexão com o banco de dados para ele. 
Por outro lado, se você não depende de atrasar a aquisição da conexão do banco de dados, o Spring Boot preparará o contexto transacional e também adquirirá a conexão do banco de dados para ele.


------------------Identificadores----------------------------------------------

Sempre que suportado, as sequências de banco de dados representam a maneira adequada (em JPA e Hibernate ORM) de gerar identificadores. O gerador SEQUENCE sustenta batching, não tem mesa, pode tirar vantagem da pré-alocação de sequências de banco de dados e suporta uma etapa incremental.

--HILO -- não utilizados se há conexão de sistemas externos----

Este algoritmo divide os domínios da sequência em grupos hi de forma síncrona . O valor hi pode ser fornecido pela sequência do banco de dados (ou pelo gerador de tabela), e seu valor inicial é configurável ( valor_inicial ).


Item 68: Como substituir corretamente equals () e hashCode ()

Se o id for gerado pelo banco....

public boolean equals (Object obj) {
    if (obj == null) {
        retorna falso;
    }
    if (this == obj) {
        return true;
    }
    if (getClass ()! = obj.getClass ()) {
        retorna falso;
    }
    IdGenBook outro = (IdGenBook) obj;
    return id! = null && id.equals (other.getId ());
}

e valor fixo pro HashCode

Retornar um valor constante de hashCode () ajudará você a atender ao requisito de Hibernate mencionado aqui, mas pode afetar o desempenho no caso de grandes Set s (ou Map s);


Contar com o Lombok @EqualsAndHashCode padrão para substituir equals () e hashCode () é uma má decisão. Outro cenário comum consiste em excluir campos como title e isbn e confiar apenas em id , @EqualsAndHashCode (exclude = {"title", "isbn"}) . Isso pode ser útil no caso de identificadores atribuídos manualmente, mas é inútil no caso de identificadores gerados por banco de dados.

Em vez só usam os @Getter e @Setter métodos e implementar equals () , hashCode () e toString () métodos como você viu neste item.

Hibernate ORM fornece suporte para declarar uma chave de negócios como um ID natural por meio da anotação @NaturalId.

----Extra----

@Transactional
public void updateAuthorRedundantSave () {
    Autor autor = authorRepository.findById (1L) .orElseThrow ();
    author.setAge (44);
    authorRepository.save (autor);
}

Verifique a linha em negrito ( authorRepository.save (autor) ) - esta linha é necessária? A resposta correta é não! Quando o aplicativo busca o autor no banco de dados, ele se torna uma instância gerenciada. Entre outras coisas, isso significa que o Hibernate cuidará de disparar as instruções UPDATE se a instância for modificada. Isso é realizado em tempo de liberação pelo mecanismo de verificação de sujeira do Hibernate. Em outras palavras, o mesmo comportamento pode ser realizado por meio do seguinte método:
@Transactional
public void updateAuthorRecommended () {
    Autor autor = authorRepository.findById (1L) .orElseThrow ();
    author.setAge (44);
}


SOFT DELETE EXEMPLO: -------------


https://github.com/vinicionagel/Hibernate-SpringBoot/tree/master/HibernateSpringBootSoftDeletes

Mostra como implementar o soft-delete de maneira muito fácil e pratica.



--------------------------------chamar procedure------

@Entidade
@NamedStoredProcedureQueries ({
    @NamedStoredProcedureQuery (
            name = "CountByGenreProcedure",
            procedureName = "COUNT_AUTHOR_BY_GENRE",
            resultClasses = {Author.class},
            parâmetros = {
                @StoredProcedureParameter (
                        nome = "p_genre",
                        type = String.class,
                        mode = ParameterMode.IN),
                @StoredProcedureParameter (
                        nome = "p_count",
                        type = Integer.class,
                        mode = ParameterMode.OUT)})
})
public class Author implementa Serializable {


Mais exemplo aqui: https://github.com/AnghelLeonard/Hibernate-SpringBoot/tree/master/HibernateSpringBootCallStoredProcedureReturnValue

--------------------MAPEANDO JSON POSTGRES---

Item 147: Como mapear com eficiência um objeto Java JSON para uma coluna JSON PostgreSQL
O item 146 abordou o tipo JSON do MySQL. Agora, vamos nos concentrar no PostgreSQL.
PostgreSQL adicionou suporte a tipos JSON a partir da versão 9.2. Os tipos JSON do PostgreSQL são json e jsonb . Os tipos JSON do PostgreSQL são representados em formato de dados binários, então você precisa usar JsonBinaryType (no item 146 , dissemos que a Biblioteca de tipos do Hibernate fornece dois tipos JSON genéricos - JsonStringType e JsonBinaryType ).
Vamos usar a entidade Author e o Book JSON Java Object . A entidade Autor está listada aqui:
@Entidade
@TypeDef (
    name = "jsonb", typeClass = JsonBinaryType.class
)
public class Author implementa Serializable {
    private static final long serialVersionUID = 1L;
    @Identificação
    @GeneratedValue (strategy = GenerationType.IDENTITY)
    ID longa privada;
    nome da string privada;
    gênero particular String;
    idade privada;
    @Type (type = "jsonb")
    @Column (columnDefinition = "jsonb") // ou, json
    livro de livro privado;
    // getters e setters omitidos por questões de brevidade
}
O objeto Java JSON do livro está listado aqui (esta não é uma entidade JPA):
public class Book implementa Serializable {
    private static final long serialVersionUID = 1L;
    Título da string privada;
    private String isbn;
    preço int privado;
    // getters e setters omitidos por questões de brevidade
}


https://github.com/AnghelLeonard/Hibernate-SpringBoot/tree/master/HibernateSpringBootJsonToPostgreSQL

-----------------------------------------------Por baixo dos panos------------------------------

O planejamento para modificar os objetos de entidade buscados é uma forma de explorar o fato de que, além de ser um cache para entidades, o Contexto de Persistência atua como um buffer de transições de estado de entidade e também como um cache write-behind transacional . No momento do flush, o Hibernate é responsável por traduzir as transições de estado das entidades em buffer em instruções DML (Data Manipulation Language) que têm como objetivo sincronizar de forma otimizada o estado persistente na memória com o banco de dados.

-------------------------------Transições de estado de entidade---------------------------------


Uma entidade JPA pode estar em qualquer um dos seguintes estados:
Transiente (ou Novo ): Uma nova entidade que é totalmente desconhecida para o banco de dados (no momento da liberação, o Hibernate emitirá uma instrução INSERT para ela).
Gerenciado (ou Persistente ): A entidade possui uma linha correspondente no banco de dados e está atualmente carregada no Contexto de Persistência. No modo de leitura e gravação, no momento do flush, o Hibernate executará o mecanismo Dirty Checking para esta entidade e, se detectar modificações, emitirá as instruções UPDATE adequadas em seu nome.
Desanexada : A entidade estava no Contexto de Persistência, mas o Contexto de Persistência foi fechado ou a entidade foi limpa / removida (quaisquer modificações de uma entidade desanexada não são propagadas automaticamente para o banco de dados).
Removido : A entidade estava no Contexto de Persistência e foi marcada para exclusão (no momento do flush, o Hibernate emitirá a instrução DELETE apropriada para excluir a linha correspondente do banco de dados).


----------------------------------------------------------------------Chave primária vs. chave única-------------


Decidir entre as chaves primárias e únicas chaves é uma tarefa que exige que você esteja ciente dos seguintes principais diferenças entre eles:
Uma chave primária identifica exclusivamente uma linha em uma tabela, enquanto uma chave exclusiva garante valores exclusivos em uma coluna.
Uma chave primária não pode ser NULL , enquanto uma chave exclusiva pode ser NULL .
Uma tabela oferece suporte a uma única chave primária, mas oferece suporte a várias chaves exclusivas.
Por padrão, uma chave primária leva a um índice clusterizado, enquanto uma chave exclusiva leva a um índice não clusterizado.
Uma chave primária pode ser composta (combinando várias colunas na mesma tabela, incluindo colunas que têm chaves exclusivas), enquanto uma chave exclusiva pode ser usada para tornar várias colunas exclusivas juntas (restrição exclusiva composta).
Uma chave primária não pode ser excluída / modificada, enquanto uma chave exclusiva pode ser excluída / modificada.
Uma chave primária é construída por meio de uma restrição de chave primária e uma restrição exclusiva (a última é adicionada automaticamente), enquanto uma chave exclusiva é construída por meio de uma restrição exclusiva (a restrição exclusiva garante que não haja valores duplicados nessa coluna).

------------------------------------------------------------------------------------------------------------------LIKE x igual (=)


Há um debate sobre o uso do operador LIKE versus igual ( = ) .
O operador LIKE é útil para correspondência de string flexível, enquanto equals ( = ) é útil quando você não precisa de curingas. As posições dos curingas nas expressões LIKE podem ter um impacto significativo na escolha do plano de execução e no intervalo do índice que precisa ser verificado. No caso do operador LIKE , como regra geral, você deve colocar curingas o mais tarde possível na correspondência de padrões e tentar evitar curingas na primeira posição. Isso pode desencadear uma verificação completa de tabela / índice e, como consequência, uma penalidade de desempenho.


Como um princípio básico:
Coloque os curingas o mais tarde possível e nunca na primeira posição
Tente fornecer um predicado de acesso “consistente”

-----------------------------------------------------------------------------------------------UNION vs. UNION ALL e JOIN Flavors----------------------------------

Primeiro, vamos dar uma olhada rápida em UNION vs. UNION ALL :
UNION remove duplicatas (ele executa um DISTINCT no conjunto de resultados), enquanto UNION ALL não remove duplicatas.
Se você souber que todos os registros retornados são exclusivos, use UNION ALL em vez de UNION .
UNION tem muito menos desempenho, especialmente se o número de duplicatas for grande. Por outro lado, transferir mais dados (duplicatas) pela rede pode ser mais lento do que aplicar DISTINCT e transferir menos dados.
UNION classifica a saída final, enquanto UNION ALL não (para classificação, você precisa especificar ORDER BY ).


--------------------------------------INDICES-------------

Como regra geral, para criar o conjunto adequado de índices, tente fazer o seguinte:
Obtenha a lista de consultas SQL a serem usadas
Estime a frequência de cada consulta SQL
Tente pontuar a importância de cada consulta SQL
Tendo essas três coordenadas, encontre o conjunto adequado de índices que resulta nas maiores otimizações e no menor número de trade-offs.

Esta dica destaca o segundo item da seção anterior, “estime a frequência de cada consulta”. As consultas SQL usadas com mais frequência devem ter prioridade para indexação. Se as consultas SQL usadas com mais frequência forem otimizadas, é mais provável que você obtenha o desempenho ideal do aplicativo.
Como regra geral, crie índices para as consultas SQL mais usadas (muito exploradas) e crie índices com base em predicados.

É altamente recomendável que você crie um índice em cada restrição de chave estrangeira na tabela filha.Enquanto o índice exclusivo para a
chave primária é criado automaticamente, o índice exclusivo para a chave estrangeira é de responsabilidade do administrador do banco de
dados ou dos desenvolvedores. Em outras palavras, se o banco de dados não cria índices automaticamente para as chaves estrangeiras (
por exemplo, SQL Server), então os índices devem ser criados manualmente pelo administrador do banco de dados ou pelos desenvolvedores.

=-=-=-=-Não adivinhe os índices=-=-=-=-

Adicionar colunas para acesso somente índice
Adicionar colunas para acesso apenas ao índice é uma técnica conhecida como sobrecarga de índice .
Basicamente, você cria um índice contendo todas as colunas necessárias para satisfazer a consulta.
Isso significa que a consulta não exigirá dados do espaço de tabela. Portanto, requer menos operações de E / S.


O nível de isolamento READ_COMMITTED afirma que uma transação não pode ler dados não confirmados de outras transações simultâneas.

------@Transactional (isolamento = Isolation.REPEATABLE_READ)

Como o próprio nome sugere, o nível de isolamento REPEATABLE_READ afirma que uma transação lê o mesmo resultado em várias leituras.
Por exemplo, uma transação que lê um registro do banco de dados várias vezes obtém o mesmo resultado em cada leitura.

Exemplo:

Etapa 1: John e Mary selecionam o preço do Maserati em suas próprias transações.
Etapa 2: John atualiza o preço de $ 65.000 para $ 85.000 (no MySQL, isso é permitido).
Etapa 3: Maria seleciona o preço novamente como $ 65.000.
Etapa 4: John confirma sua transação com sucesso e o preço se torna $ 85.000.
Etapa 5: Maria seleciona o preço novamente como $ 65.000 (o MySQL evita leituras não repetíveis).


@Transactional (isolamento = Isolation.SERIALIZABLE)

O nível de isolamento SERIALIZABLE é muito rígido, mas a compensação é com o desempenho. Ele usa bloqueio em todos os níveis,
portanto, é equivalente a uma execução serial. Teoricamente falando, SERIALIZABLE deveria prevenir todos os fenômenos ,
mas na prática as coisas não são bem assim. Os detalhes de implementação são específicos para cada banco de dados e
alguns deles ainda estão sujeitos a diversos fenômenos (veja a menção da tabela anterior). A Figura F-4 mostra o serializável em ação.

Exemplo:

Etapa 1: John seleciona o preço do Maserati em sua transação.
Etapa 2: Maria tenta selecionar o mesmo registro em sua transação, mas a transação de John bloqueou esses dados. Portanto, a transação de Maria é suspensa até que o bloqueio seja liberado.
Etapa 3: John atualiza o preço para $ 85.000.
Etapa 4: a transação de Maria ainda está suspensa.
Etapa 5: A transação de John foi confirmada com sucesso e o bloqueio foi liberado.
Etapa 6: a transação de Maria é retomada e ela lê o preço como $ 85.000.


@Transactional (propagation = Propagation.REQUIRED) - Propagation.REQUIRED

Se não houver transação física existente, o contêiner Spring criará uma
Se houver uma transação física existente, os métodos anotados com REQUIRE participarão desta transação física
Cada método anotado com REQUIRED demarca uma transação lógica e essas transações lógicas participam da mesma transação física
Cada transação lógica tem seu próprio escopo, mas, no caso desse mecanismo de propagação, todos esses escopos são mapeados para a mesma transação física

Considere as duas transações lógicas a seguir (ou pense nisso como uma transação lógica externa contendo uma transação lógica interna):
@Transactional (propagation = Propagation.REQUIRED)
public void insertFirstAuthor () {
    Autor autor = novo Autor ();
    author.setName ("Joana Nimar");
    authorRepository.save (autor);
    insertSecondAuthorService.insertSecondAuthor ();
}
@Transactional (propagation = Propagation.REQUIRED)
public void insertSecondAuthor () {
    Autor autor = novo Autor ();
    author.setName ("Alicia Tom");
    authorRepository.save (autor);
    if (new Random (). nextBoolean ()) {
        lance new RuntimeException ("DummyException: isso deve causar
            reversão de ambas as inserções! ");
    }
}

Explicação:

Etapa 1: Quando o método insertFirstAuthor () é chamado, não há transação física. Spring cria um para executar a transação lógica externa - o código deste método.

Etapa 2: quando insertSecondAuthor () é chamado a partir de insertFirstAuthor () , há uma transação física existente. Portanto, o Spring convida a transação lógica interna representada pelo método insertSecondAuthor () a participar dessa transação física .

Etapa 3: Se a RuntimeException causada aleatoriamente no final do método insertSecondAuthor () for lançada, o Spring irá reverter ambas as transações lógicas. Portanto, nada será inserido no banco de dados .



